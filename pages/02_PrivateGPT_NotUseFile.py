from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOllama
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
import streamlit as st

# page_title
st.set_page_config(
    page_title="PrivateGPT_NotUseFile",
    page_icon="ğŸ“ƒ",
)


# ì±„íŒ… ì½œë°± í•¸ë“¤ëŸ¬ í´ë˜ìŠ¤
class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)


# Ollama ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ê¸°ëŠ¥ êµ¬í˜„
# Ollama ì„œë²„(ë¡œì»¬, ì„œë²„ ëª¨ë‘)ì™€ í†µì‹ ì´ ì•ˆëœë‹¤ë©´, ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ
llm = ChatOllama(
    model="mistral:latest",
    temperature=0.1,
    streaming=True,
    callbacks=[
        ChatCallbackHandler(),
    ],
)


# ì‚¬ìš©ìì™€ AIì˜ ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_message(message, role):
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    st.session_state["messages"].append({"message": message, "role": role})


# ë©”ì‹œì§€ ì „ì†¡ ë° í™”ë©´ì— í‘œì‹œ í•¨ìˆ˜
def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)


# ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í™”ë©´ì— í‘œì‹œí•˜ëŠ” í•¨ìˆ˜
def paint_history():
    for message in st.session_state.get("messages", []):
        send_message(
            message["message"],
            message["role"],
            save=False,
        )


# ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
prompt = ChatPromptTemplate.from_template("""{question}""")

# ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª© ë° ì„¤ëª…
st.title("PrivateGPT")

st.markdown(
    """
Welcome!
            
Use this chatbot to interact with an AI!
"""
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ëŒ€í™” ì‹œì‘
send_message("I'm ready! Ask away!", "ai", save=False)
paint_history()
message = st.chat_input("What's your question?")
if message:
    send_message(message, "human")
    chain = (
        {
            "question": RunnablePassthrough(),
        }
        | prompt
        | llm
    )
    with st.chat_message("ai"):
        chain.invoke(message)
